{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1AuFx45HXyN4XSw9T0mLs1wcRq24wvWWM",
      "authorship_tag": "ABX9TyODJ3SNJw6ISeurFASJ3APB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwdb/tensorflow2.0-tutorial/blob/master/text/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMI-EfFv-X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2a54a836-9ab2-49ff-f1d3-99b0c2fd47a5"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 22 04:39:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5iF7QosKec",
        "colab_type": "code",
        "outputId": "2909f6bf-e484-4ac3-d81c-0745fae3dbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "    # TPU detection\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    print('ERROR: Not connected to a TPU runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "ERROR: Not connected to a TPU runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9R7FS63xA4n",
        "colab_type": "code",
        "outputId": "41a25baf-40df-497f-d2b3-8fcab7569a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start_token, end_token = '<start>', '<end>'\n",
        "\n",
        "corpus_path = '/content/drive/My Drive/corpus'\n",
        "dataset_path = '/content/drive/My Drive/corpus/tokenize_dataset.txt'\n",
        "\n",
        "examples = []\n",
        "if not os.path.exists(dataset_path):\n",
        "        # 根据白空格文件生成训练集\n",
        "    for name in os.listdir(corpus_path):\n",
        "        if not name.startswith('corpus_'):\n",
        "            continue\n",
        "        print('reading copurs: ', name)\n",
        "\n",
        "        with open(corpus_path + '/' + name, encoding='utf8') as f:\n",
        "            for line in f.readlines()[:300]:\n",
        "                line = line.split('\\t\\t')[1].strip()\n",
        "                for subline in re.split('[:：，,。？！!、\"“；（）《》【】\\[\\]()]/\\w+', line):\n",
        "                    if subline.count('/') < 3:\n",
        "                        continue\n",
        "                    items = [item for item in subline.strip().split() if '/' in item]\n",
        "                    words = [item.split('/')[0].strip('[').strip(']') for item in items]\n",
        "                    chars = list(''.join(words))\n",
        "                    start = 0\n",
        "                    for i in range(len(words)):\n",
        "                        # 生成正例训练样本\n",
        "                        if len(words[i]) > 1 and '[' not in words[i]:\n",
        "                            pos_example = chars.copy()\n",
        "                            pos_example.insert(start + len(words[i]), end_token)\n",
        "                            pos_example.insert(start, start_token)\n",
        "                            examples.append([pos_example, 1])\n",
        "\n",
        "                        # 生成负例训练样本\n",
        "                        if i > 0 and len(words[i - 1]) > 1:\n",
        "                            neg_example = chars.copy()\n",
        "                            neg_example.insert(start + len(words[i]), end_token)\n",
        "                            neg_example.insert(start - 1, start_token)\n",
        "                            examples.append([neg_example, 0])\n",
        "\n",
        "                        start += len(words[i])\n",
        "\n",
        "    print('total examples: ', len(examples))\n",
        "\n",
        "    with open(dataset_path, 'w', encoding='utf8') as f:\n",
        "        examples = ['%s\\t%s\\n' % (' '.join(exp), lab) for exp, lab in examples]\n",
        "        f.writelines(examples)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading copurs:  corpus_分_20140804152950.txt\n",
            "reading copurs:  corpus_年_20140804152049.txt\n",
            "reading copurs:  corpus_都_20140804161305.txt\n",
            "reading copurs:  corpus_他_20140804145948.txt\n",
            "reading copurs:  corpus_哼_20140804155348.txt\n",
            "reading copurs:  corpus_等_20140804145652.txt\n",
            "reading copurs:  corpus_为_20140804162548.txt\n",
            "reading copurs:  corpus_就_20140804154053.txt\n",
            "reading copurs:  corpus_已_20140804145809.txt\n",
            "reading copurs:  corpus_小_20140804162225.txt\n",
            "reading copurs:  corpus_我_20140801175536.txt\n",
            "reading copurs:  corpus_做_20140804145913.txt\n",
            "reading copurs:  corpus_们_20140804150145.txt\n",
            "reading copurs:  corpus_日_20140804152715.txt\n",
            "reading copurs:  corpus_啊_20140804155434.txt\n",
            "reading copurs:  corpus_也_20140804161420.txt\n",
            "reading copurs:  corpus_的_20140801175641.txt\n",
            "reading copurs:  corpus_不_20140804161122.txt\n",
            "reading copurs:  corpus_会_20140804163313.txt\n",
            "reading copurs:  corpus_跟_20140804144542.txt\n",
            "reading copurs:  corpus_这_20140804151112.txt\n",
            "reading copurs:  corpus_和_20140804144647.txt\n",
            "reading copurs:  corpus_请_20140804164617.txt\n",
            "reading copurs:  corpus_含_20140804145849.txt\n",
            "reading copurs:  corpus_中_20140804162714.txt\n",
            "reading copurs:  corpus_于_20140804162934.txt\n",
            "reading copurs:  corpus_个_20140804161952.txt\n",
            "reading copurs:  corpus_时_20140804152757.txt\n",
            "reading copurs:  corpus_是_20140804155542.txt\n",
            "reading copurs:  corpus_吧_20140804154602.txt\n",
            "reading copurs:  corpus_对_20140804163154.txt\n",
            "reading copurs:  corpus_此_20140804164315.txt\n",
            "reading copurs:  corpus_了_20140804154734.txt\n",
            "reading copurs:  corpus_呢_20140804154406.txt\n",
            "reading copurs:  corpus_该_20140804150815.txt\n",
            "reading copurs:  corpus_在_20140804153953.txt\n",
            "reading copurs:  corpus_嘛_20140804155120.txt\n",
            "reading copurs:  corpus_那_20140804151535.txt\n",
            "reading copurs:  corpus_多_20140804153813.txt\n",
            "reading copurs:  corpus_还_20140804161726.txt\n",
            "reading copurs:  corpus_并_20140804145525.txt\n",
            "reading copurs:  corpus_或_20140804164435.txt\n",
            "reading copurs:  corpus_地_20140804144200.txt\n",
            "reading copurs:  corpus_什_20140804151723.txt\n",
            "reading copurs:  corpus_更_20140804145740.txt\n",
            "reading copurs:  corpus_此_20140804163920.txt\n",
            "reading copurs:  corpus_很_20140804154257.txt\n",
            "reading copurs:  corpus_第_20140804163844.txt\n",
            "reading copurs:  corpus_一_20140804162433.txt\n",
            "reading copurs:  corpus_与_20140804145124.txt\n",
            "reading copurs:  corpus_中国_20140801175458.txt\n",
            "reading copurs:  corpus_你_20140801175804.txt\n",
            "reading copurs:  corpus_看_20140804161545.txt\n",
            "reading copurs:  corpus_她_20140804150058.txt\n",
            "reading copurs:  corpus_又_20140804154203.txt\n",
            "reading copurs:  corpus_有_20140804162058.txt\n",
            "reading copurs:  corpus_某_20140804150432.txt\n",
            "reading copurs:  corpus_秒_20140804153244.txt\n",
            "reading copurs:  corpus_月_20140804152234.txt\n",
            "reading copurs:  corpus_几_20140804153308.txt\n",
            "reading copurs:  corpus_到_20140804162325.txt\n",
            "reading copurs:  corpus_得_20140804144322.txt\n",
            "reading copurs:  corpus_把_20140804161645.txt\n",
            "reading copurs:  corpus_每_20140804151034.txt\n",
            "reading copurs:  corpus_谁_20140804151955.txt\n",
            "reading copurs:  corpus_各_20140804150941.txt\n",
            "reading copurs:  corpus_恩_20140804155515.txt\n",
            "reading copurs:  corpus_儿_20140804155241.txt\n",
            "reading copurs:  corpus_起来_20140804155200.txt\n",
            "reading copurs:  corpus_说_20140804160225.txt\n",
            "reading copurs:  corpus_及_20140804145316.txt\n",
            "reading copurs:  corpus_么_20140804151859.txt\n",
            "reading copurs:  corpus_哪_20140804151641.txt\n",
            "reading copurs:  corpus_共_20140804164511.txt\n",
            "reading copurs:  corpus_之_20140804163424.txt\n",
            "reading copurs:  corpus_着_20140804155706.txt\n",
            "reading copurs:  corpus_哇_20140804155140.txt\n",
            "reading copurs:  corpus_嗯_20140804155500.txt\n",
            "reading copurs:  corpus_都_20140804160001.txt\n",
            "reading copurs:  corpus_吗_20140804154645.txt\n",
            "reading copurs:  corpus_按_20140804164544.txt\n",
            "reading copurs:  corpus_向_20140804145358.txt\n",
            "reading copurs:  corpus_来_20140804153905.txt\n",
            "total examples:  622405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "marefrmR_vuB",
        "colab_type": "code",
        "outputId": "1a43fbbe-03af-4a08-c51c-ae7758c414c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "max_len = 32\n",
        "\n",
        "with open(dataset_path, encoding='utf8') as f:\n",
        "    raw_dataset = [line.strip().split('\\t') for line in f.readlines()]\n",
        "    raw_dataset = [example for example in raw_dataset if example[0].count(' ') < max_len]\n",
        "    np.random.seed(2)\n",
        "    np.random.shuffle(raw_dataset)\n",
        "\n",
        "    raw_dataset_x, raw_dataset_y = zip(*raw_dataset)\n",
        "    print(raw_dataset_x[:3], raw_dataset_y[:3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('市 <start> 人 大 常 委 会 <end> 主 任 吴 振 主 持 了 会 议', '铁 托 总 统 谈 到 南 斯 拉 夫 <start> 目 前 <end> 正 在 进 行 的 教 育 改 革', '耳 <start> 环 的 <end> 花 式 品 种 也 渐 增 多') ('1', '1', '0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9EmCD6qd53i",
        "colab_type": "code",
        "outputId": "341cd1f1-d437-495c-e655-4454d119431e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_num_words = 10000\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(max_num_words, filters='')\n",
        "tokenizer.fit_on_texts(raw_dataset_x)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(['你 的 名 字'])\n",
        "for sequence in sequences:\n",
        "    print(sequence)\n",
        "    print([tokenizer.index_word[c] for c in sequence])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[480, 3, 157, 866]\n",
            "['你', '的', '名', '字']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvZiKww45Ao_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38107b08-9126-4e41-fb64-bb087b16712b"
      },
      "source": [
        "import json\n",
        "\n",
        "json_path = '/content/drive/My Drive/model/tokenizer/tokenizer.json'\n",
        "with open(json_path, 'w', encoding='utf8') as f:\n",
        "    json_string = tokenizer.to_json()\n",
        "    json.dump(json_string, f)\n",
        "\n",
        "with open(json_path, encoding='utf8') as f:\n",
        "    json_string = json.load(f)\n",
        "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(json_string)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(['你 的 名 字'])\n",
        "for sequence in sequences:\n",
        "    print(sequence)\n",
        "    print([t.index_word[c] for c in sequence])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[480, 3, 157, 866]\n",
            "['你', '的', '名', '字']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdTeihEGgYrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_x = tokenizer.texts_to_sequences(raw_dataset_x)\n",
        "dataset_x = tf.keras.preprocessing.sequence.pad_sequences(dataset_x, max_len, padding='post')\n",
        "dataset_y = np.array(raw_dataset_y, dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpsp8BrMGcV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_size = 20000\n",
        "buffer_size = 50000\n",
        "if tpu:\n",
        "    batch_size = 64 * tpu_strategy.num_replicas_in_sync\n",
        "else:\n",
        "    batch_size = 256\n",
        "n_train = len(dataset_x) - valid_size\n",
        "steps_per_epoch = n_train // batch_size\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((dataset_x, dataset_y))\n",
        "\n",
        "train_dataset = dataset.skip(valid_size)\\\n",
        "    .shuffle(buffer_size)\\\n",
        "    .batch(batch_size, drop_remainder=True)\\\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_dataset = dataset.take(valid_size)\\\n",
        "    .batch(batch_size)\\\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# next(iter(train_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faS9ysykaYA7",
        "colab_type": "code",
        "outputId": "b08d385b-4865-440e-bcff-c0baca77d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_size = 256\n",
        "\n",
        "def make_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_size),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        # tf.keras.layers.LSTM(256),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)), \n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(1),               \n",
        "    ])\n",
        "    \n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        # loss='binary_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "        # optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if tpu:\n",
        "    with tpu_strategy.scope():\n",
        "        model = make_model()\n",
        "else:\n",
        "    model = make_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 256)         1024000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1050624   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,650,049\n",
            "Trainable params: 3,650,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfpgDC0lJx1-",
        "colab_type": "code",
        "outputId": "e599da07-73c4-4210-e838-da48e0d9edb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "\"\"\"\n",
        "validation_steps: 每个epoch验证的次数，若验证集如果没有repeat，\n",
        "    则数据量低于validation_steps * batch_size时报错\n",
        "    \n",
        "steps_per_epoch: 每个epoch的步数，训练集repeat，必须设置该参数\n",
        "\"\"\"\n",
        "model.fit(\n",
        "    train_dataset, \n",
        "    epochs=20,\n",
        "    # steps_per_epoch=steps_per_epoch, 训练集需要repeat\n",
        "    # validation_steps=100, \n",
        "    validation_data=valid_dataset)\n",
        "\n",
        "checkpoint_path = '/content/drive/My Drive/model/tokenizer/tokenizer_model.ckpt'\n",
        "if not os.path.exists(os.path.dirname(checkpoint_path)):\n",
        "    os.makedirs(os.path.dirname(checkpoint_path))\n",
        "    \n",
        "model.save_weights(checkpoint_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.4632 - accuracy: 0.7325 - val_loss: 0.2430 - val_accuracy: 0.9079\n",
            "Epoch 2/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.1605 - accuracy: 0.9373 - val_loss: 0.1055 - val_accuracy: 0.9602\n",
            "Epoch 3/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0990 - accuracy: 0.9629 - val_loss: 0.0877 - val_accuracy: 0.9692\n",
            "Epoch 4/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0822 - accuracy: 0.9697 - val_loss: 0.0792 - val_accuracy: 0.9689\n",
            "Epoch 5/20\n",
            "2242/2242 [==============================] - 100s 45ms/step - loss: 0.0706 - accuracy: 0.9744 - val_loss: 0.0695 - val_accuracy: 0.9759\n",
            "Epoch 6/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.0631 - val_accuracy: 0.9774\n",
            "Epoch 7/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0566 - accuracy: 0.9796 - val_loss: 0.0621 - val_accuracy: 0.9773\n",
            "Epoch 8/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0518 - accuracy: 0.9817 - val_loss: 0.0612 - val_accuracy: 0.9772\n",
            "Epoch 9/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 0.0600 - val_accuracy: 0.9812\n",
            "Epoch 10/20\n",
            "2242/2242 [==============================] - 100s 44ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 0.0558 - val_accuracy: 0.9815\n",
            "Epoch 11/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0532 - val_accuracy: 0.9826\n",
            "Epoch 12/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.0538 - val_accuracy: 0.9836\n",
            "Epoch 13/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.0505 - val_accuracy: 0.9840\n",
            "Epoch 14/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.0503 - val_accuracy: 0.9837\n",
            "Epoch 15/20\n",
            "2242/2242 [==============================] - 98s 44ms/step - loss: 0.0291 - accuracy: 0.9899 - val_loss: 0.0478 - val_accuracy: 0.9857\n",
            "Epoch 16/20\n",
            "2242/2242 [==============================] - 98s 44ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0486 - val_accuracy: 0.9844\n",
            "Epoch 17/20\n",
            "2242/2242 [==============================] - 98s 44ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0471 - val_accuracy: 0.9869\n",
            "Epoch 18/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0451 - val_accuracy: 0.9881\n",
            "Epoch 19/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0473 - val_accuracy: 0.9874\n",
            "Epoch 20/20\n",
            "2242/2242 [==============================] - 99s 44ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0470 - val_accuracy: 0.9869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ddbc8bcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvsQl14zfvvR",
        "colab_type": "code",
        "outputId": "2a283bd5-a66b-4633-c197-156716c0abd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# model.load_weights(checkpoint_path)\n",
        "sentence = ['三 <start> 年 暂 时 <end> 困 难 时']\n",
        "encoded_sentence = tokenizer.texts_to_sequences(sentence)\n",
        "encoded_sentence = tf.keras.preprocessing.sequence.pad_sequences(encoded_sentence, max_len, padding='post')\n",
        "# encoded_sentence[0] = encoded_sentence[0] + (max_len - len(encoded_sentence)) * [0]\n",
        "model.predict(encoded_sentence)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-9.40421]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVKl_fv6LtoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# buffer_size = 50000\n",
        "# batch_size = 128\n",
        "# start_token, end_token = '<start>', '<end>'\n",
        "# # if tpu:\n",
        "# #     batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "# # else:\n",
        "# #     batch_size = 64\n",
        "# # steps_per_epoch = buffer_size // batch_size\n",
        "# steps_per_epoch = buffer_size // batch_size\n",
        "# embedding_size = 256\n",
        "# vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# dataset = tf.data.TextLineDataset(dataset_path)\n",
        "\n",
        "# def encode(text):\n",
        "#     text, label = text.numpy().decode(encoding='utf8').split('\\t')\n",
        "#     x = tokenizer.texts_to_sequences([text])[0]\n",
        "#     y = tf.cast(int(label), tf.int64)\n",
        "#     return x, y\n",
        "\n",
        "# def tf_encode(text):\n",
        "#     x, y = tf.py_function(encode, [text], [tf.int64, tf.int64])\n",
        "#     x.set_shape([None])\n",
        "#     y.set_shape([])\n",
        "#     return x, y\n",
        "\n",
        "# # dataset = dataset.map(tf_encode).filter(lambda x, y: tf.logical_and(\n",
        "# #     tf.size(x) >= 5, tf.size(x) <= 50))\n",
        "# dataset = dataset.map(tf_encode)\n",
        "# valid_dataset = dataset.take(10000).padded_batch(batch_size)\n",
        "# train_dataset = dataset.skip(10000)\\\n",
        "#     .cache()\\\n",
        "#     .shuffle(buffer_size)\\\n",
        "#     .padded_batch(batch_size)\\\n",
        "#     .prefetch(tf.data.experimental.AUTOTUNE)\\\n",
        "#     .repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qbDEfdddpYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}